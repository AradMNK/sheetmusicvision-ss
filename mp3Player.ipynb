{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086ee908-2101-4bc5-b371-733f9a0f303f",
   "metadata": {},
   "source": [
    "Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff7cd73-4931-4f94-95bc-01f6e20c72ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pydub\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.wavfile import read, write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8cea3-0c71-46b1-ab1c-78f62ee7f6b6",
   "metadata": {},
   "source": [
    "These are my own implemented functions. 'dotted' outputs 1.5 times the duration, and getDurations outputs the amount of samples in an array so as to be used later.\n",
    "Indices are:\n",
    "    Whole note = 0\n",
    "    Dotted whole note = 1\n",
    "    Half note = 2\n",
    "    Dotted half note = 3\n",
    "    Quarter note = 4\n",
    "    Dotted quarter note = 5\n",
    "    etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee67f1c8-1aed-4453-8130-ce54e1d4bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDurations(tempo, fs):\n",
    "    whole_note = 4*60*fs/tempo\n",
    "    durs = np.array([[whole_note/(2**i),dotted(whole_note/(2**i))] for i in range(6)])\n",
    "    \n",
    "    return durs.flatten()\n",
    "\n",
    "def dotted(dur):\n",
    "    return dur*1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc67937-d0ba-4f22-8646-21e09b83f2f2",
   "metadata": {},
   "source": [
    "These are the functions from helper.ipynb but edited so as to implement tempo into the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1ac59c-caf3-41ca-8a16-73321b4159be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_wave(f, n, fs):\n",
    "    x = np.linspace(0, 2*np.pi, n)\n",
    "    xp = np.linspace(0, -1*(n*ring/fs), n)\n",
    "    y = np.sin(x*f*(n/fs))*np.exp(xp)\n",
    "    z = np.zeros([n, 2])\n",
    "    z[:, 0] = y\n",
    "    z[:, 1] = y\n",
    "    return z\n",
    "\n",
    "def play_note(note_id, octave, dur, fs):\n",
    "    if (note_id < 3) :\n",
    "        octave += 1\n",
    "    y = sin_wave(notes_base[note_id]*2**octave, int(notes_duration[dur]), fs)\n",
    "    sd.play(y, fs)\n",
    "    sd.wait()\n",
    "    return \n",
    "\n",
    "def put_note(note_id, octave, dur, fs):\n",
    "    if (note_id < 3) :\n",
    "        octave += 1\n",
    "    y = sin_wave(notes_base[note_id]*2**octave, int(notes_duration[dur]), fs)\n",
    "    return y\n",
    "\n",
    "def get_music(music_notes, fs):\n",
    "    m = []\n",
    "    for item in music_notes:\n",
    "        y = put_note(item[0], item[1], item[2], fs)\n",
    "        m.append(y)\n",
    "    m = np.concatenate(m, 0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427972d-0e98-42f4-860c-5761d7e0ed9d",
   "metadata": {},
   "source": [
    "This is a testbench. We set A4 = 440 Hz and the tempo and ringing values for the sine wave, get the note duration array from the tempo and then proceed to play the riff and the C Major scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1cf979-c5d8-4ce7-b7aa-a59421634fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_base = 2**(np.arange(12)/12)*27.5 # A0; A4= 440 Hz\n",
    "tempo = 150\n",
    "ring = 7 # how long the sine wave rings. lower value = more ringing/sustain\n",
    "fs = 44100\n",
    "notes_duration = getDurations(tempo,fs)\n",
    "\"\"\"\n",
    "    Whole note = 0\n",
    "    Dotted whole note = 1\n",
    "    Half note = 2\n",
    "    Dotted half note = 3\n",
    "    Quarter note = 4\n",
    "    Dotted quarter note = 5\n",
    "    etc.\n",
    "\"\"\"\n",
    "notes_ann = ['A', 'A#', 'B', 'C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'G#']\n",
    "\n",
    "Scale = [[3,4,4], [5,4,4], [7,4,4], [8,4,4], [10,4,4], [0,4,4], [2,4,4], [3,5,4], \n",
    "        [2,4,4], [0,4,4], [10,4,4], [8,4,4], [7,4,4], [5,4,4], [3,4,4]]\n",
    "theRiff = [ [5,4,6], [7,4,6], [8,4,6], [10,4,6], [7,4,4], [3,4,6], [5,4,2] ]\n",
    "\n",
    "y = get_music(theRiff, fs)\n",
    "sd.play(y, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3c132-1ca2-4a92-b0e6-5c9c519e3d09",
   "metadata": {},
   "source": [
    "Exporting the results to .wav files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f6d03a-3ed0-47a6-800d-c1f502d1faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"the riff.wav\", fs, y.astype(np.float32))\n",
    "write(\"C Major scale.wav\", fs, get_music(theRiff, fs).astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239181ef-103f-482a-9163-8f0e115d5ab5",
   "metadata": {},
   "source": [
    "We now intend on adding reverb using the convultional technique. We first obtain the impulse response of a \"Large Hall\" and then use the convolution operation to apply it to our signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f188c39-e46b-42c7-a273-68b09055045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arad\\AppData\\Local\\Temp\\ipykernel_7648\\4250220074.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  samplerate,impulse_response = read(impulse_file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impulse_file_path = 'impulse.wav'\n",
    "samplerate,impulse_response = read(impulse_file_path)\n",
    "samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c5dc5-f607-4967-b3f4-3d0d92570582",
   "metadata": {},
   "source": [
    "As you can see, the sample rate is not 44.1kHz. The project sample rate will be set to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2947c5c-94a2-492e-a494-429a448e29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_base = 2**(np.arange(12)/12)*27.5 # A0; A4= 440 Hz\n",
    "tempo = 260\n",
    "ring = 7 # how long the sine wave rings. lower value = more ringing/sustain\n",
    "fs = samplerate\n",
    "notes_duration = getDurations(tempo,fs)\n",
    "\n",
    "jane_maryam = [[0, 4, 4],\n",
    " [2, 4, 4],\n",
    " [3, 5, 4],\n",
    " [5, 5, 4],\n",
    " [7, 5, 4],\n",
    " [7, 5, 4],\n",
    " [7, 5, 4],\n",
    " [0, 5, 4],\n",
    " [7, 5, 2],\n",
    " [7, 5, 4],\n",
    " [0, 5, 4],\n",
    " [7, 5, 4],\n",
    " [0, 5, 4],\n",
    " [7, 5, 2],\n",
    " [7, 5, 4],\n",
    " [8, 5, 4],\n",
    " [5, 5, 4],\n",
    " [7, 5, 4],\n",
    " [3, 5, 2],\n",
    " [5, 5, 4],\n",
    " [7, 5, 4],\n",
    " [3, 5, 4],\n",
    " [5, 5, 4],\n",
    " [2, 4, 2],\n",
    " [3, 5, 4],\n",
    " [5, 5, 4],\n",
    " [2, 4, 4],\n",
    " [3, 5, 4],\n",
    " [0, 4, 2],\n",
    " [3, 5, 4],\n",
    " [2, 4, 4],\n",
    " [10, 4, 4],\n",
    " [2, 4, 4],\n",
    " [10, 4, 2],\n",
    " [0, 4, 3],\n",
    " [3, 5, 3],\n",
    " [3, 5, 4],\n",
    " [2, 4, 4],\n",
    " [0, 4, 4],\n",
    " [2, 4, 4],\n",
    " [10, 4, 2],\n",
    " [0, 4, 3]]\n",
    "\n",
    "reverbless = get_music(jane_maryam, fs)\n",
    "sd.play(reverbless, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c954183-eb1a-4829-a7b0-12eec7d44920",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = np.convolve(reverbless[:,0],impulse_response[:,0])\n",
    "right = np.convolve(reverbless[:,1],impulse_response[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "166f1329-6628-415e-884c-72e567d56704",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = np.zeros( (len(left),2))\n",
    "reverb[:,0] = left\n",
    "reverb[:,1] = right\n",
    "reverb /= np.max(np.abs(reverb),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a135587-80b2-4cdf-842a-7ff06da6642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(reverb, fs)\n",
    "write(\"Jane maryam with reverb.wav\", fs, reverb.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10962531-aee8-4351-b6ad-ac852fb6b1f0",
   "metadata": {},
   "source": [
    "We can now put it in a function. Beware that the convolutions will take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2bf2cdb-4f3b-450d-bf7d-c86eb0f68b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverbify(audio, impulse_response_filepath): # check for fs yourself\n",
    "    left = np.convolve(audio[:,0],impulse_response[:,0])\n",
    "    right = np.convolve(audio[:,1],impulse_response[:,1])\n",
    "    reverb = np.zeros( (len(left),2))\n",
    "    reverb[:,0] = left\n",
    "    reverb[:,1] = right\n",
    "    reverb /= np.max(np.abs(reverb),axis=0) # because of clipping\n",
    "    return reverb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
